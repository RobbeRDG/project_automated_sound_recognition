{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "def setup_file_system(in_colab):\n",
    "    if in_colab:\n",
    "        from google.colab import drive\n",
    "\n",
    "        # Set the base and mount path\n",
    "        MOUNT_PATH_DRIVE = '/content/drive'\n",
    "        BASE_PATH = join(\n",
    "            MOUNT_PATH_DRIVE, \n",
    "            \"MyDrive/project_asr\"\n",
    "        )\n",
    "\n",
    "        # Mount the google drive\n",
    "        drive.mount(MOUNT_PATH_DRIVE)\n",
    "\n",
    "        return BASE_PATH\n",
    "\n",
    "    else:\n",
    "        return \"/workspaces/project_automated_sound_recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import chdir\n",
    "from os.path import join\n",
    "\n",
    "# Method to check if the notebook is running in colab or local\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# Set the base path of the project\n",
    "BASE_PATH = setup_file_system(IN_COLAB)\n",
    "\n",
    "# Set the base path of the project\n",
    "chdir(join(BASE_PATH, \"src/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "# Utils\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import wandb\n",
    "import sys\n",
    "import importlib\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import datetime\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# DL libraries\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torch.utils.data \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# User libraries\n",
    "from dataset.audio_sample_dataset import AudioSampleDataset\n",
    "from model.baseline_model import BaselineModel\n",
    "from trainer.trainer import train_classification_model\n",
    "from validator.validator import validate_classification_model\n",
    "from util import config, util_functions, model_management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_augmentations = {\n",
    "    'pitch_shift': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'noise': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'mixup': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'freq_mask': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'time_mask': {\n",
    "        'enabled': False,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 1 - Pitch shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = {\n",
    "    'pitch_shift': {\n",
    "        'enabled': True,\n",
    "        'p': 0.5,\n",
    "        'min_semitones': -4, \n",
    "        \"max_semitones\": 4,\n",
    "    },\n",
    "    'noise': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'mixup': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'freq_mask': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'time_mask': {\n",
    "        'enabled': False,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and test data\n",
    "train_dataset = AudioSampleDataset(\n",
    "        join(BASE_PATH, config.TRAIN_DATA_PATH),\n",
    "        augmentations\n",
    "    )\n",
    "test_dataset = AudioSampleDataset(\n",
    "        join(BASE_PATH, config.TEST_DATA_PATH),\n",
    "        test_augmentations\n",
    "    )\n",
    "\n",
    "# Place in dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Get the model\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(in_features=512, out_features= 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=256, out_features=len(config.LABELS)),\n",
    "    nn.Softmax(dim= 1)\n",
    ")\n",
    "model.to(config.DEVICE)\n",
    "\n",
    "# Set the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LR)\n",
    "\n",
    "# Set the loss fn\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the gradient scaler\n",
    "grad_scaler = torch.cuda.amp.grad_scaler.GradScaler()\n",
    "\n",
    "# Setup weights and biasses\n",
    "wandb.login()\n",
    "\n",
    "# Get the current time for the checkpoint name\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Set the wandb experiment name\n",
    "experiment_name = util_functions.generate_run_name_from_config(augmentations)\n",
    "\n",
    "# Start wandb\n",
    "wandb.init(\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    "    project=\"project_asr\", \n",
    "    name=experiment_name, \n",
    "    config={\n",
    "        \"learning_rate\": config.LR,\n",
    "        \"batch_size\": config.BATCH_SIZE,\n",
    "        \"epochs\": config.EPOCHS,\n",
    "        \"augmentations\": json.dumps(augmentations),\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the variables to keep track of the best model\n",
    "best_validation_loss = 10000\n",
    "best_model_state = model.state_dict()\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "  # Set the model in training mode\n",
    "  model.train()\n",
    "  \n",
    "  # Train the model\n",
    "  total_train_loss_this_epoch = train_classification_model(\n",
    "      model,\n",
    "      optimizer,\n",
    "      criteria,\n",
    "      grad_scaler,\n",
    "      train_dataloader\n",
    "  )\n",
    "  \n",
    "  # Set the model in evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  # Validate the model\n",
    "  total_val_loss_this_epoch, pred_classes, true_classes = validate_classification_model(\n",
    "      model,\n",
    "      criteria,\n",
    "      test_dataloader,\n",
    "  )\n",
    "\n",
    "  # Calculate the loss values\n",
    "  train_loss_this_epoch = total_train_loss_this_epoch/len(train_dataloader.dataset)\n",
    "  val_loss_this_epoch = total_val_loss_this_epoch/len(test_dataloader.dataset)\n",
    "\n",
    "  # Calculate the accuracy\n",
    "  acc_avg = accuracy_score(true_classes, pred_classes)\n",
    "\n",
    "  # Calculate acc per class\n",
    "  matrix = confusion_matrix(true_classes, pred_classes)\n",
    "  acc_per_class = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "\n",
    "  # Log the train loss this epoch\n",
    "  wandb.log({\n",
    "      'train_loss': train_loss_this_epoch,\n",
    "      'val_loss': val_loss_this_epoch,\n",
    "      'acc': acc_avg,\n",
    "      'acc_airport': acc_per_class[0],\n",
    "      'acc_shopping_mall': acc_per_class[1],\n",
    "      'acc_metro_station': acc_per_class[3],\n",
    "      'acc_street_pedestrian': acc_per_class[3],\n",
    "      'acc_public_square': acc_per_class[4],\n",
    "      'acc_street_traffic': acc_per_class[5],\n",
    "      'acc_tram': acc_per_class[6],\n",
    "      'acc_bus': acc_per_class[7],\n",
    "      'acc_metro': acc_per_class[8],\n",
    "      'acc_park': acc_per_class[9],\n",
    "  })\n",
    "\n",
    "  print(f'epoch: {epoch}, train_loss: {train_loss_this_epoch}, val_loss: {val_loss_this_epoch}, acc: {acc_avg}')\n",
    "\n",
    "  # If this is the best performing model yet, save it\n",
    "  if val_loss_this_epoch < best_validation_loss:\n",
    "    # Update the score\n",
    "    best_validation_loss = val_loss_this_epoch\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    # Save the model\n",
    "    checkpoint_path = join(\n",
    "      BASE_PATH, \n",
    "      config.MODEL_CHECKPOINT_PATH, \n",
    "      f'{experiment_name}.pth'\n",
    "    )\n",
    "    best_model_state = model_management.save_model(model, checkpoint_path, False, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "# Save the final model\n",
    "checkpoint_path = join(\n",
    "    BASE_PATH, \n",
    "    config.MODEL_CHECKPOINT_PATH, \n",
    "    f'{experiment_name}.pth'\n",
    ")\n",
    "best_model_state = model_management.save_model(model, checkpoint_path, True, f'model_{experiment_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the run as finished\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 2 - Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = {\n",
    "    'pitch_shift': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'noise': {\n",
    "        'enabled': True,\n",
    "        'p': 0.5,\n",
    "        'min_amplitude': 0.001,\n",
    "        'max_amplitude': 0.015,\n",
    "    },\n",
    "    'mixup': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'freq_mask': {\n",
    "        'enabled': False\n",
    "    },\n",
    "    'time_mask': {\n",
    "        'enabled': False,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and test data\n",
    "train_dataset = AudioSampleDataset(\n",
    "        join(BASE_PATH, config.TRAIN_DATA_PATH),\n",
    "        augmentations\n",
    "    )\n",
    "test_dataset = AudioSampleDataset(\n",
    "        join(BASE_PATH, config.TEST_DATA_PATH),\n",
    "        test_augmentations\n",
    "    )\n",
    "\n",
    "# Place in dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Get the model\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(in_features=512, out_features= 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=256, out_features=len(config.LABELS)),\n",
    "    nn.Softmax(dim= 1)\n",
    ")\n",
    "model.to(config.DEVICE)\n",
    "\n",
    "# Set the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LR)\n",
    "\n",
    "# Set the loss fn\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the gradient scaler\n",
    "grad_scaler = torch.cuda.amp.grad_scaler.GradScaler()\n",
    "\n",
    "# Setup weights and biasses\n",
    "wandb.login()\n",
    "\n",
    "# Get the current time for the checkpoint name\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Set the wandb experiment name\n",
    "experiment_name = util_functions.generate_run_name_from_config(augmentations)\n",
    "\n",
    "# Start wandb\n",
    "wandb.init(\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    "    project=\"project_asr\", \n",
    "    name=experiment_name, \n",
    "    config={\n",
    "        \"learning_rate\": config.LR,\n",
    "        \"batch_size\": config.BATCH_SIZE,\n",
    "        \"epochs\": config.EPOCHS,\n",
    "        \"augmentations\": json.dumps(augmentations),\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the variables to keep track of the best model\n",
    "best_validation_loss = 10000\n",
    "best_model_state = model.state_dict()\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "  # Set the model in training mode\n",
    "  model.train()\n",
    "  \n",
    "  # Train the model\n",
    "  total_train_loss_this_epoch = train_classification_model(\n",
    "      model,\n",
    "      optimizer,\n",
    "      criteria,\n",
    "      grad_scaler,\n",
    "      train_dataloader\n",
    "  )\n",
    "  \n",
    "  # Set the model in evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  # Validate the model\n",
    "  total_val_loss_this_epoch, pred_classes, true_classes = validate_classification_model(\n",
    "      model,\n",
    "      criteria,\n",
    "      test_dataloader,\n",
    "  )\n",
    "\n",
    "  # Calculate the loss values\n",
    "  train_loss_this_epoch = total_train_loss_this_epoch/len(train_dataloader.dataset)\n",
    "  val_loss_this_epoch = total_val_loss_this_epoch/len(test_dataloader.dataset)\n",
    "\n",
    "  # Calculate the accuracy\n",
    "  acc_avg = accuracy_score(true_classes, pred_classes)\n",
    "\n",
    "  # Calculate acc per class\n",
    "  matrix = confusion_matrix(true_classes, pred_classes)\n",
    "  acc_per_class = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "\n",
    "  # Log the train loss this epoch\n",
    "  wandb.log({\n",
    "      'train_loss': train_loss_this_epoch,\n",
    "      'val_loss': val_loss_this_epoch,\n",
    "      'acc': acc_avg,\n",
    "      'acc_airport': acc_per_class[0],\n",
    "      'acc_shopping_mall': acc_per_class[1],\n",
    "      'acc_metro_station': acc_per_class[3],\n",
    "      'acc_street_pedestrian': acc_per_class[3],\n",
    "      'acc_public_square': acc_per_class[4],\n",
    "      'acc_street_traffic': acc_per_class[5],\n",
    "      'acc_tram': acc_per_class[6],\n",
    "      'acc_bus': acc_per_class[7],\n",
    "      'acc_metro': acc_per_class[8],\n",
    "      'acc_park': acc_per_class[9],\n",
    "  })\n",
    "\n",
    "  print(f'epoch: {epoch}, train_loss: {train_loss_this_epoch}, val_loss: {val_loss_this_epoch}, acc: {acc_avg}')\n",
    "\n",
    "  # If this is the best performing model yet, save it\n",
    "  if val_loss_this_epoch < best_validation_loss:\n",
    "    # Update the score\n",
    "    best_validation_loss = val_loss_this_epoch\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    # Save the model\n",
    "    checkpoint_path = join(\n",
    "      BASE_PATH, \n",
    "      config.MODEL_CHECKPOINT_PATH, \n",
    "      f'{experiment_name}.pth'\n",
    "    )\n",
    "    best_model_state = model_management.save_model(model, checkpoint_path, False, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "# Save the final model\n",
    "checkpoint_path = join(\n",
    "    BASE_PATH, \n",
    "    config.MODEL_CHECKPOINT_PATH, \n",
    "    f'{experiment_name}.pth'\n",
    ")\n",
    "best_model_state = model_management.save_model(model, checkpoint_path, True, f'model_{experiment_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the run as finished\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 3 - Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = {\n",
    "    'pitch_shift': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'noise': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'mixup': {\n",
    "        'enabled': True,\n",
    "        'p': 0.5,\n",
    "        'alpha': 0.2,\n",
    "    },\n",
    "    'freq_mask': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'time_mask': {\n",
    "        'enabled': False,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and test data\n",
    "train_dataset = AudioSampleDataset(\n",
    "        join(BASE_PATH, config.TRAIN_DATA_PATH),\n",
    "        augmentations\n",
    "    )\n",
    "test_dataset = AudioSampleDataset(\n",
    "        join(BASE_PATH, config.TEST_DATA_PATH),\n",
    "        test_augmentations\n",
    "    )\n",
    "\n",
    "# Place in dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Get the model\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(in_features=512, out_features= 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=256, out_features=len(config.LABELS)),\n",
    "    nn.Softmax(dim= 1)\n",
    ")\n",
    "model.to(config.DEVICE)\n",
    "\n",
    "# Set the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LR)\n",
    "\n",
    "# Set the loss fn\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the gradient scaler\n",
    "grad_scaler = torch.cuda.amp.grad_scaler.GradScaler()\n",
    "\n",
    "# Setup weights and biasses\n",
    "wandb.login()\n",
    "\n",
    "# Get the current time for the checkpoint name\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Set the wandb experiment name\n",
    "experiment_name = util_functions.generate_run_name_from_config(augmentations)\n",
    "\n",
    "# Start wandb\n",
    "wandb.init(\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    "    project=\"project_asr\", \n",
    "    name=experiment_name, \n",
    "    config={\n",
    "        \"learning_rate\": config.LR,\n",
    "        \"batch_size\": config.BATCH_SIZE,\n",
    "        \"epochs\": config.EPOCHS,\n",
    "        \"augmentations\": json.dumps(augmentations),\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the variables to keep track of the best model\n",
    "best_validation_loss = 10000\n",
    "best_model_state = model.state_dict()\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "  # Set the model in training mode\n",
    "  model.train()\n",
    "  \n",
    "  # Train the model\n",
    "  total_train_loss_this_epoch = train_classification_model(\n",
    "      model,\n",
    "      optimizer,\n",
    "      criteria,\n",
    "      grad_scaler,\n",
    "      train_dataloader\n",
    "  )\n",
    "  \n",
    "  # Set the model in evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  # Validate the model\n",
    "  total_val_loss_this_epoch, pred_classes, true_classes = validate_classification_model(\n",
    "      model,\n",
    "      criteria,\n",
    "      test_dataloader,\n",
    "  )\n",
    "\n",
    "  # Calculate the loss values\n",
    "  train_loss_this_epoch = total_train_loss_this_epoch/len(train_dataloader.dataset)\n",
    "  val_loss_this_epoch = total_val_loss_this_epoch/len(test_dataloader.dataset)\n",
    "\n",
    "  # Calculate the accuracy\n",
    "  acc_avg = accuracy_score(true_classes, pred_classes)\n",
    "\n",
    "  # Calculate acc per class\n",
    "  matrix = confusion_matrix(true_classes, pred_classes)\n",
    "  acc_per_class = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "\n",
    "  # Log the train loss this epoch\n",
    "  wandb.log({\n",
    "      'train_loss': train_loss_this_epoch,\n",
    "      'val_loss': val_loss_this_epoch,\n",
    "      'acc': acc_avg,\n",
    "      'acc_airport': acc_per_class[0],\n",
    "      'acc_shopping_mall': acc_per_class[1],\n",
    "      'acc_metro_station': acc_per_class[3],\n",
    "      'acc_street_pedestrian': acc_per_class[3],\n",
    "      'acc_public_square': acc_per_class[4],\n",
    "      'acc_street_traffic': acc_per_class[5],\n",
    "      'acc_tram': acc_per_class[6],\n",
    "      'acc_bus': acc_per_class[7],\n",
    "      'acc_metro': acc_per_class[8],\n",
    "      'acc_park': acc_per_class[9],\n",
    "  })\n",
    "\n",
    "  print(f'epoch: {epoch}, train_loss: {train_loss_this_epoch}, val_loss: {val_loss_this_epoch}, acc: {acc_avg}')\n",
    "\n",
    "  # If this is the best performing model yet, save it\n",
    "  if val_loss_this_epoch < best_validation_loss:\n",
    "    # Update the score\n",
    "    best_validation_loss = val_loss_this_epoch\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    # Save the model\n",
    "    checkpoint_path = join(\n",
    "      BASE_PATH, \n",
    "      config.MODEL_CHECKPOINT_PATH, \n",
    "      f'{experiment_name}.pth'\n",
    "    )\n",
    "    best_model_state = model_management.save_model(model, checkpoint_path, False, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "# Save the final model\n",
    "checkpoint_path = join(\n",
    "    BASE_PATH, \n",
    "    config.MODEL_CHECKPOINT_PATH, \n",
    "    f'{experiment_name}.pth'\n",
    ")\n",
    "best_model_state = model_management.save_model(model, checkpoint_path, True, f'model_{experiment_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the run as finished\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 4 - Frequency mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = {\n",
    "    'pitch_shift': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'noise': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'mixup': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'freq_mask': {\n",
    "        'enabled': True,\n",
    "        'p': 0.5,\n",
    "        'freq_mask_param': 5,\n",
    "    },\n",
    "    'time_mask': {\n",
    "        'enabled': False,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and test data\n",
    "train_dataset = AudioSampleDataset(\n",
    "        join(BASE_PATH, config.TRAIN_DATA_PATH),\n",
    "        augmentations\n",
    "    )\n",
    "test_dataset = AudioSampleDataset(\n",
    "        join(BASE_PATH, config.TEST_DATA_PATH),\n",
    "        test_augmentations\n",
    "    )\n",
    "\n",
    "# Place in dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrobberdg\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/project_automated_sound_recognition/src/wandb/run-20221214_201250-1tn1cty9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/robberdg/project_asr/runs/1tn1cty9\" target=\"_blank\">128_1e-05_f_14_12_2022_20_12_50</a></strong> to <a href=\"https://wandb.ai/robberdg/project_asr\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/robberdg/project_asr/runs/1tn1cty9?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1458f086b370>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Get the model\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(in_features=512, out_features= 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=256, out_features=len(config.LABELS)),\n",
    "    nn.Softmax(dim= 1)\n",
    ")\n",
    "model.to(config.DEVICE)\n",
    "\n",
    "# Set the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LR)\n",
    "\n",
    "# Set the loss fn\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the gradient scaler\n",
    "grad_scaler = torch.cuda.amp.grad_scaler.GradScaler()\n",
    "\n",
    "# Setup weights and biasses\n",
    "wandb.login()\n",
    "\n",
    "# Get the current time for the checkpoint name\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Set the wandb experiment name\n",
    "experiment_name = util_functions.generate_run_name_from_config(augmentations)\n",
    "\n",
    "# Start wandb\n",
    "wandb.init(\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    "    project=\"project_asr\", \n",
    "    name=experiment_name, \n",
    "    config={\n",
    "        \"learning_rate\": config.LR,\n",
    "        \"batch_size\": config.BATCH_SIZE,\n",
    "        \"epochs\": config.EPOCHS,\n",
    "        \"augmentations\": json.dumps(augmentations),\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [02:22<00:00,  1.80s/it]\n",
      "100%|██████████| 2000/2000 [00:28<00:00, 71.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 0.01814651746749878, val_loss: 2.2915825871825217, acc: 0.1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [02:11<00:00,  1.66s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_loss: 0.017910743808746337, val_loss: 2.2627825811505318, acc: 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.31s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train_loss: 0.017559250521659853, val_loss: 2.236168146252632, acc: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:44<00:00,  1.32s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 74.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, train_loss: 0.01727432541847229, val_loss: 2.2169164804816246, acc: 0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:44<00:00,  1.33s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, train_loss: 0.017056730914115907, val_loss: 2.200456899523735, acc: 0.2965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:45<00:00,  1.33s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 74.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, train_loss: 0.016834811139106752, val_loss: 2.1828980457782747, acc: 0.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:46<00:00,  1.35s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, train_loss: 0.016572837567329406, val_loss: 2.156868134200573, acc: 0.3235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:44<00:00,  1.32s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, train_loss: 0.01630070023536682, val_loss: 2.136728289723396, acc: 0.3385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:45<00:00,  1.33s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, train_loss: 0.016089766156673433, val_loss: 2.1262704927921297, acc: 0.3445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:52<00:00,  1.42s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, train_loss: 0.015895993053913118, val_loss: 2.1153980679512023, acc: 0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:49<00:00,  1.38s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, train_loss: 0.01577858909368515, val_loss: 2.1118579864501954, acc: 0.3475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:46<00:00,  1.35s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, train_loss: 0.015602548229694367, val_loss: 2.10611387270689, acc: 0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:46<00:00,  1.35s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, train_loss: 0.015459991836547851, val_loss: 2.10539204877615, acc: 0.3465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [02:02<00:00,  1.55s/it]\n",
      "100%|██████████| 2000/2000 [00:28<00:00, 69.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, train_loss: 0.01537439020872116, val_loss: 2.097815777182579, acc: 0.356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [02:02<00:00,  1.55s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 74.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, train_loss: 0.015245545840263367, val_loss: 2.097628143072128, acc: 0.3525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:46<00:00,  1.35s/it]\n",
      "100%|██████████| 2000/2000 [00:28<00:00, 71.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, train_loss: 0.01512396047115326, val_loss: 2.09709947013855, acc: 0.3545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:45<00:00,  1.33s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, train_loss: 0.015054734325408936, val_loss: 2.091011386394501, acc: 0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:44<00:00,  1.33s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 72.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, train_loss: 0.014940799009799957, val_loss: 2.0928771351575852, acc: 0.3595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.31s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, train_loss: 0.01481889442205429, val_loss: 2.0973688906431196, acc: 0.356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.31s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, train_loss: 0.014731411814689637, val_loss: 2.0879828950166703, acc: 0.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.31s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 74.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, train_loss: 0.014697124087810516, val_loss: 2.088620763063431, acc: 0.3665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21, train_loss: 0.014594499349594116, val_loss: 2.088681205809116, acc: 0.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 74.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22, train_loss: 0.01450316255092621, val_loss: 2.088168570280075, acc: 0.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 71.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23, train_loss: 0.014392021918296813, val_loss: 2.085147741436958, acc: 0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24, train_loss: 0.014292443299293517, val_loss: 2.083078311264515, acc: 0.3735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25, train_loss: 0.014245361053943634, val_loss: 2.07923191177845, acc: 0.3785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26, train_loss: 0.01409940789937973, val_loss: 2.078546951293945, acc: 0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27, train_loss: 0.014044156455993653, val_loss: 2.0779198294878007, acc: 0.3785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:45<00:00,  1.33s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 74.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28, train_loss: 0.013974104201793671, val_loss: 2.0756359495520593, acc: 0.3805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:44<00:00,  1.32s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29, train_loss: 0.013898640072345734, val_loss: 2.078744370341301, acc: 0.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 74.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30, train_loss: 0.01378265597820282, val_loss: 2.0761222140789033, acc: 0.3795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.31s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31, train_loss: 0.01374194734096527, val_loss: 2.0764910928606986, acc: 0.3785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.31s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32, train_loss: 0.013668573951721191, val_loss: 2.080089163184166, acc: 0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.31s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33, train_loss: 0.013544558370113372, val_loss: 2.0759106133580207, acc: 0.3745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34, train_loss: 0.013529223120212555, val_loss: 2.074337935745716, acc: 0.382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35, train_loss: 0.01350767458677292, val_loss: 2.0735676637887956, acc: 0.3765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.31s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36, train_loss: 0.013399025285243988, val_loss: 2.0791171301603315, acc: 0.3715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 72.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37, train_loss: 0.01335705522298813, val_loss: 2.07734620565176, acc: 0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38, train_loss: 0.013285946786403656, val_loss: 2.078475517630577, acc: 0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39, train_loss: 0.013275709509849548, val_loss: 2.076055369436741, acc: 0.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the variables to keep track of the best model\n",
    "best_validation_loss = 10000\n",
    "best_model_state = model.state_dict()\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "  # Set the model in training mode\n",
    "  model.train()\n",
    "  \n",
    "  # Train the model\n",
    "  total_train_loss_this_epoch = train_classification_model(\n",
    "      model,\n",
    "      optimizer,\n",
    "      criteria,\n",
    "      grad_scaler,\n",
    "      train_dataloader\n",
    "  )\n",
    "  \n",
    "  # Set the model in evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  # Validate the model\n",
    "  total_val_loss_this_epoch, pred_classes, true_classes = validate_classification_model(\n",
    "      model,\n",
    "      criteria,\n",
    "      test_dataloader,\n",
    "  )\n",
    "\n",
    "  # Calculate the loss values\n",
    "  train_loss_this_epoch = total_train_loss_this_epoch/len(train_dataloader.dataset)\n",
    "  val_loss_this_epoch = total_val_loss_this_epoch/len(test_dataloader.dataset)\n",
    "\n",
    "  # Calculate the accuracy\n",
    "  acc_avg = accuracy_score(true_classes, pred_classes)\n",
    "\n",
    "  # Calculate acc per class\n",
    "  matrix = confusion_matrix(true_classes, pred_classes)\n",
    "  acc_per_class = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "\n",
    "  # Log the train loss this epoch\n",
    "  wandb.log({\n",
    "      'train_loss': train_loss_this_epoch,\n",
    "      'val_loss': val_loss_this_epoch,\n",
    "      'acc': acc_avg,\n",
    "      'acc_airport': acc_per_class[0],\n",
    "      'acc_shopping_mall': acc_per_class[1],\n",
    "      'acc_metro_station': acc_per_class[3],\n",
    "      'acc_street_pedestrian': acc_per_class[3],\n",
    "      'acc_public_square': acc_per_class[4],\n",
    "      'acc_street_traffic': acc_per_class[5],\n",
    "      'acc_tram': acc_per_class[6],\n",
    "      'acc_bus': acc_per_class[7],\n",
    "      'acc_metro': acc_per_class[8],\n",
    "      'acc_park': acc_per_class[9],\n",
    "  })\n",
    "\n",
    "  print(f'epoch: {epoch}, train_loss: {train_loss_this_epoch}, val_loss: {val_loss_this_epoch}, acc: {acc_avg}')\n",
    "\n",
    "  # If this is the best performing model yet, save it\n",
    "  if val_loss_this_epoch < best_validation_loss:\n",
    "    # Update the score\n",
    "    best_validation_loss = val_loss_this_epoch\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    # Save the model\n",
    "    checkpoint_path = join(\n",
    "      BASE_PATH, \n",
    "      config.MODEL_CHECKPOINT_PATH, \n",
    "      f'{experiment_name}.pth'\n",
    "    )\n",
    "    best_model_state = model_management.save_model(model, checkpoint_path, False, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "# Save the final model\n",
    "checkpoint_path = join(\n",
    "    BASE_PATH, \n",
    "    config.MODEL_CHECKPOINT_PATH, \n",
    "    f'{experiment_name}.pth'\n",
    ")\n",
    "best_model_state = model_management.save_model(model, checkpoint_path, True, f'model_{experiment_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▂▃▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>acc_airport</td><td>▃▂▁▂▄▄▅▅▆▅▄▄▄▅▄▅▆▆▆▆▅▆▇▇▇██▇▇▇▇█▇█▇█▇▆▆█</td></tr><tr><td>acc_bus</td><td>█▆▆▆▆▅▄▂▁▁▁▁▁▂▂▄▃▃▃▄▄▃▄▄▄▄▄▄▄▃▃▄▃▃▃▃▃▄▃▃</td></tr><tr><td>acc_metro</td><td>▁▁▃▄▅▄▄▇█████▇▇▆▆▇▇▆▇▆▆▆▆▆▅▅▅▆▅▅▅▅▅▅▅▄▅▅</td></tr><tr><td>acc_metro_station</td><td>▁▁▁▁▁▁▂▂▂▄▅▇▇▇▇█▇▇█▇████▇▆▇▇▇▆▇▆▆▆▆▅▆▆▇▆</td></tr><tr><td>acc_park</td><td>▁██▆▇▇▆▇▇▆▅▆▅▅█▅▇▆▄▆▆█▅▅▅▇▅▆▆▅▄▅▄▃▄▅▃▄▅▄</td></tr><tr><td>acc_public_square</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▄▅▅▅▆▇▆▆▆▇▇▇▇█▇</td></tr><tr><td>acc_shopping_mall</td><td>▁▄▆█▇▇▆▇▆▆▆▅▄▅▄▃▃▄▄▄▄▃▃▄▃▃▃▄▃▄▃▃▃▃▃▃▃▃▂▃</td></tr><tr><td>acc_street_pedestrian</td><td>▁▁▁▁▁▁▂▂▂▄▅▇▇▇▇█▇▇█▇████▇▆▇▇▇▆▇▆▆▆▆▅▆▆▇▆</td></tr><tr><td>acc_street_traffic</td><td>▁▁▁▂▅▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▇▇▇▆▆▆▆▆▆▆▆</td></tr><tr><td>acc_tram</td><td>▁▁▁▁▁▁▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train_loss</td><td>██▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▆▅▅▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.376</td></tr><tr><td>acc_airport</td><td>0.38991</td></tr><tr><td>acc_bus</td><td>0.28155</td></tr><tr><td>acc_metro</td><td>0.39548</td></tr><tr><td>acc_metro_station</td><td>0.25333</td></tr><tr><td>acc_park</td><td>0.59615</td></tr><tr><td>acc_public_square</td><td>0.19895</td></tr><tr><td>acc_shopping_mall</td><td>0.4604</td></tr><tr><td>acc_street_pedestrian</td><td>0.25333</td></tr><tr><td>acc_street_traffic</td><td>0.54369</td></tr><tr><td>acc_tram</td><td>0.37288</td></tr><tr><td>train_loss</td><td>0.01328</td></tr><tr><td>val_loss</td><td>2.07606</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">128_1e-05_f_14_12_2022_20_12_50</strong>: <a href=\"https://wandb.ai/robberdg/project_asr/runs/1tn1cty9\" target=\"_blank\">https://wandb.ai/robberdg/project_asr/runs/1tn1cty9</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221214_201250-1tn1cty9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mark the run as finished\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 5 - Time mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = {\n",
    "    'pitch_shift': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'noise': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'mixup': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'freq_mask': {\n",
    "        'enabled': False,\n",
    "    },\n",
    "    'time_mask': {\n",
    "        'enabled': True,\n",
    "        'p': 0.5,\n",
    "        'time_mask_param': 10,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and test data\n",
    "train_dataset = AudioSampleDataset(\n",
    "        join(BASE_PATH, config.TRAIN_DATA_PATH),\n",
    "        augmentations\n",
    "    )\n",
    "test_dataset = AudioSampleDataset(\n",
    "        join(BASE_PATH, config.TEST_DATA_PATH),\n",
    "        test_augmentations\n",
    "    )\n",
    "\n",
    "# Place in dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrobberdg\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspaces/project_automated_sound_recognition/src/wandb/run-20221214_214612-2hm9t8zc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/robberdg/project_asr/runs/2hm9t8zc\" target=\"_blank\">128_1e-05_t_14_12_2022_21_46_12</a></strong> to <a href=\"https://wandb.ai/robberdg/project_asr\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/robberdg/project_asr/runs/2hm9t8zc?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1461b2c672e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear gpu cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Get the model\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(in_features=512, out_features= 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=256, out_features=len(config.LABELS)),\n",
    "    nn.Softmax(dim= 1)\n",
    ")\n",
    "model.to(config.DEVICE)\n",
    "\n",
    "# Set the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LR)\n",
    "\n",
    "# Set the loss fn\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the gradient scaler\n",
    "grad_scaler = torch.cuda.amp.grad_scaler.GradScaler()\n",
    "\n",
    "# Setup weights and biasses\n",
    "wandb.login()\n",
    "\n",
    "# Get the current time for the checkpoint name\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Set the wandb experiment name\n",
    "experiment_name = util_functions.generate_run_name_from_config(augmentations)\n",
    "\n",
    "# Start wandb\n",
    "wandb.init(\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    "    project=\"project_asr\", \n",
    "    name=experiment_name, \n",
    "    config={\n",
    "        \"learning_rate\": config.LR,\n",
    "        \"batch_size\": config.BATCH_SIZE,\n",
    "        \"epochs\": config.EPOCHS,\n",
    "        \"augmentations\": json.dumps(augmentations),\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [02:40<00:00,  2.04s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 72.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_loss: 0.018141668725013733, val_loss: 2.292042660832405, acc: 0.1445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [02:23<00:00,  1.82s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 74.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_loss: 0.017910553908348083, val_loss: 2.26892687857151, acc: 0.1835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:44<00:00,  1.32s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train_loss: 0.017683639931678773, val_loss: 2.24932501655817, acc: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 74.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, train_loss: 0.017436096334457397, val_loss: 2.2325205284953116, acc: 0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, train_loss: 0.017161810445785523, val_loss: 2.211484442412853, acc: 0.2845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 76.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, train_loss: 0.016766514205932618, val_loss: 2.184859692454338, acc: 0.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:41<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, train_loss: 0.016464751052856445, val_loss: 2.1618051878213884, acc: 0.315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:41<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 74.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, train_loss: 0.016218554663658142, val_loss: 2.145610965192318, acc: 0.3265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 76.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, train_loss: 0.01599307942390442, val_loss: 2.1321071806550025, acc: 0.336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, train_loss: 0.015852154910564423, val_loss: 2.120288865327835, acc: 0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, train_loss: 0.015682553064823152, val_loss: 2.1173216458559034, acc: 0.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, train_loss: 0.015538578248023988, val_loss: 2.1099030094146727, acc: 0.347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.31s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, train_loss: 0.015442651891708374, val_loss: 2.1052153358459473, acc: 0.3505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 72.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, train_loss: 0.015305491745471954, val_loss: 2.101655939280987, acc: 0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 74.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, train_loss: 0.015188426458835601, val_loss: 2.098711725473404, acc: 0.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:41<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, train_loss: 0.01503308893442154, val_loss: 2.096118675708771, acc: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:41<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, train_loss: 0.014900859892368317, val_loss: 2.096585577905178, acc: 0.3645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, train_loss: 0.014809891498088836, val_loss: 2.088887168586254, acc: 0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 76.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, train_loss: 0.01467970403432846, val_loss: 2.091006124317646, acc: 0.3615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, train_loss: 0.014605163741111756, val_loss: 2.0858768304586413, acc: 0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:41<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, train_loss: 0.014485987842082977, val_loss: 2.084383416175842, acc: 0.3795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 74.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21, train_loss: 0.014381754732131958, val_loss: 2.086199783146381, acc: 0.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:41<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22, train_loss: 0.014300580620765686, val_loss: 2.0848352729678155, acc: 0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23, train_loss: 0.01418385283946991, val_loss: 2.0823787527680397, acc: 0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24, train_loss: 0.014111380183696747, val_loss: 2.085057491660118, acc: 0.3715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25, train_loss: 0.014019909417629242, val_loss: 2.085042282998562, acc: 0.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26, train_loss: 0.013966081202030182, val_loss: 2.082048446893692, acc: 0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:41<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 71.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27, train_loss: 0.013895944571495056, val_loss: 2.081335670530796, acc: 0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 74.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28, train_loss: 0.01381717883348465, val_loss: 2.082044200718403, acc: 0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:41<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 74.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29, train_loss: 0.013695433342456818, val_loss: 2.0812873858213425, acc: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30, train_loss: 0.01365081398487091, val_loss: 2.086374474108219, acc: 0.3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31, train_loss: 0.01356910458803177, val_loss: 2.084042126476765, acc: 0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:43<00:00,  1.31s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 76.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32, train_loss: 0.013517132556438447, val_loss: 2.0856276401281355, acc: 0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33, train_loss: 0.013433049929141998, val_loss: 2.0852910627126695, acc: 0.3675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:41<00:00,  1.29s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34, train_loss: 0.013408041489124297, val_loss: 2.08972912812233, acc: 0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:41<00:00,  1.28s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35, train_loss: 0.013387720715999604, val_loss: 2.086798738062382, acc: 0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:42<00:00,  1.30s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 74.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36, train_loss: 0.013295482325553894, val_loss: 2.087268812954426, acc: 0.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:45<00:00,  1.34s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 75.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37, train_loss: 0.013295716190338135, val_loss: 2.0949540239572526, acc: 0.3555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:45<00:00,  1.33s/it]\n",
      "100%|██████████| 2000/2000 [00:27<00:00, 73.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38, train_loss: 0.01322052208185196, val_loss: 2.0898290684819223, acc: 0.3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [01:44<00:00,  1.32s/it]\n",
      "100%|██████████| 2000/2000 [00:26<00:00, 74.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39, train_loss: 0.01315424132347107, val_loss: 2.088029297530651, acc: 0.3635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the variables to keep track of the best model\n",
    "best_validation_loss = 10000\n",
    "best_model_state = model.state_dict()\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "  # Set the model in training mode\n",
    "  model.train()\n",
    "  \n",
    "  # Train the model\n",
    "  total_train_loss_this_epoch = train_classification_model(\n",
    "      model,\n",
    "      optimizer,\n",
    "      criteria,\n",
    "      grad_scaler,\n",
    "      train_dataloader\n",
    "  )\n",
    "  \n",
    "  # Set the model in evaluation mode\n",
    "  model.eval()\n",
    "\n",
    "  # Validate the model\n",
    "  total_val_loss_this_epoch, pred_classes, true_classes = validate_classification_model(\n",
    "      model,\n",
    "      criteria,\n",
    "      test_dataloader,\n",
    "  )\n",
    "\n",
    "  # Calculate the loss values\n",
    "  train_loss_this_epoch = total_train_loss_this_epoch/len(train_dataloader.dataset)\n",
    "  val_loss_this_epoch = total_val_loss_this_epoch/len(test_dataloader.dataset)\n",
    "\n",
    "  # Calculate the accuracy\n",
    "  acc_avg = accuracy_score(true_classes, pred_classes)\n",
    "\n",
    "  # Calculate acc per class\n",
    "  matrix = confusion_matrix(true_classes, pred_classes)\n",
    "  acc_per_class = matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "\n",
    "  # Log the train loss this epoch\n",
    "  wandb.log({\n",
    "      'train_loss': train_loss_this_epoch,\n",
    "      'val_loss': val_loss_this_epoch,\n",
    "      'acc': acc_avg,\n",
    "      'acc_airport': acc_per_class[0],\n",
    "      'acc_shopping_mall': acc_per_class[1],\n",
    "      'acc_metro_station': acc_per_class[3],\n",
    "      'acc_street_pedestrian': acc_per_class[3],\n",
    "      'acc_public_square': acc_per_class[4],\n",
    "      'acc_street_traffic': acc_per_class[5],\n",
    "      'acc_tram': acc_per_class[6],\n",
    "      'acc_bus': acc_per_class[7],\n",
    "      'acc_metro': acc_per_class[8],\n",
    "      'acc_park': acc_per_class[9],\n",
    "  })\n",
    "\n",
    "  print(f'epoch: {epoch}, train_loss: {train_loss_this_epoch}, val_loss: {val_loss_this_epoch}, acc: {acc_avg}')\n",
    "\n",
    "  # If this is the best performing model yet, save it\n",
    "  if val_loss_this_epoch < best_validation_loss:\n",
    "    # Update the score\n",
    "    best_validation_loss = val_loss_this_epoch\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    # Save the model\n",
    "    checkpoint_path = join(\n",
    "      BASE_PATH, \n",
    "      config.MODEL_CHECKPOINT_PATH, \n",
    "      f'{experiment_name}.pth'\n",
    "    )\n",
    "    best_model_state = model_management.save_model(model, checkpoint_path, False, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "\n",
    "# Save the final model\n",
    "checkpoint_path = join(\n",
    "    BASE_PATH, \n",
    "    config.MODEL_CHECKPOINT_PATH, \n",
    "    f'{experiment_name}.pth'\n",
    ")\n",
    "best_model_state = model_management.save_model(model, checkpoint_path, True, f'model_{experiment_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▂▃▄▅▆▆▆▇▇▇▇▇▇████▇███████████▇███▇▇█▇▇█</td></tr><tr><td>acc_airport</td><td>▁▁▁▁▁▁▁▁▁▁▂▃▃▃▄▄▄▃▄▄▄▄▅▅▅▅▆▆▇▅▇▆▇▇▇▇████</td></tr><tr><td>acc_bus</td><td>▃▄▆▆▄▂▂▃▂▁▂▂▂▂▃▂▂▄▄▅▆▆▆▆▇▇▇▇██▇▇▇█▆▇█▆█▇</td></tr><tr><td>acc_metro</td><td>▁▁▂▂▂▃▃▅▇██▇█▇▇▇▇▆▇▇▆▆▆▇▆▆▆▇▆▆▆▆▅▅▆▆▅▆▆▅</td></tr><tr><td>acc_metro_station</td><td>▄▆▇▇▄▃▄▄▄▅▅▅▅▇█▇▆▅▅▅▆▅▄▃▃▃▄▂▂▃▂▂▂▃▂▂▂▃▂▁</td></tr><tr><td>acc_park</td><td>▁▆▆▇▆▆▆▆▆█▄▇▇█▆▆▆▇▅▆▆▇▆▇▇▅▅▆▆▅▄▆▅▄▅▅▆▁▃▅</td></tr><tr><td>acc_public_square</td><td>██▆▃▂▁▁▁▁▁▁▁▂▂▃▃▄▄▅▅▅▆▅▅▇▆▇▆▇▇▆▇██▇▇█▇▇▇</td></tr><tr><td>acc_shopping_mall</td><td>▁▁▂▅▆▇▇▇███▇▇▇▇▇▆▇▇▆▆▆▆▆▆▆▆▆▆▅▆▅▅▆▅▅▅▆▅▅</td></tr><tr><td>acc_street_pedestrian</td><td>▄▆▇▇▄▃▄▄▄▅▅▅▅▇█▇▆▅▅▅▆▅▄▃▃▃▄▂▂▃▂▂▂▃▂▂▂▃▂▁</td></tr><tr><td>acc_street_traffic</td><td>▁▁▁▃▆█████████▇███▇▇█▇▇█▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>acc_tram</td><td>▁▂▂▄▆▇█▇▇▆▆▆▅▆▆▆▆▅▅▅▅▅▄▅▅▄▅▅▄▅▅▄▄▄▅▄▅▅▄▅</td></tr><tr><td>train_loss</td><td>██▇▇▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▇▆▅▄▄▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.3635</td></tr><tr><td>acc_airport</td><td>0.28899</td></tr><tr><td>acc_bus</td><td>0.32039</td></tr><tr><td>acc_metro</td><td>0.32768</td></tr><tr><td>acc_metro_station</td><td>0.2</td></tr><tr><td>acc_park</td><td>0.59615</td></tr><tr><td>acc_public_square</td><td>0.20942</td></tr><tr><td>acc_shopping_mall</td><td>0.50495</td></tr><tr><td>acc_street_pedestrian</td><td>0.2</td></tr><tr><td>acc_street_traffic</td><td>0.52913</td></tr><tr><td>acc_tram</td><td>0.37288</td></tr><tr><td>train_loss</td><td>0.01315</td></tr><tr><td>val_loss</td><td>2.08803</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">128_1e-05_t_14_12_2022_21_46_12</strong>: <a href=\"https://wandb.ai/robberdg/project_asr/runs/2hm9t8zc\" target=\"_blank\">https://wandb.ai/robberdg/project_asr/runs/2hm9t8zc</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221214_214612-2hm9t8zc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mark the run as finished\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
